One ordinal feature

import numpy as np
import pandas as pd
from scipy.optimize import fmin_l_bfgs_b
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score

def encode_categories(df, cols):
    Zs, lookups = [], {}
    for c in cols:
        codes, levels = pd.factorize(df[c], sort=True)
        Zs.append(codes)
        lookups[c] = dict(enumerate(levels))
    return Zs, lookups

def build_cov_ezgp(X_pair, Z_pair, params, shapes):
    X1, X2 = X_pair
    Z1_list, Z2_list = Z_pair
    p, q, b_list = shapes['p'], shapes['q'], shapes['b_list']
    idx = 0
    sigma0 = params[idx]; idx += 1
    theta0 = params[idx:idx+p]; idx += p
    sigma_hs, theta_hs = [], []
    for h in range(q):
        sigma_hs.append(params[idx]); idx += 1
        m_h = b_list[h]
        th = params[idx: idx + p*m_h].reshape(m_h, p)
        idx += p*m_h
        theta_hs.append(th)
    var_n = params[-1]
    def rbf(Xa, Xb, ls):
        diff2 = ((Xa[:,None,:] - Xb[None,:,:])**2)/(2*ls**2)
        return np.exp(-diff2.sum(axis=-1))
    K0 = (sigma0**2)*rbf(X1, X2, theta0)
    K_add = np.zeros_like(K0)
    for h in range(q):
        Z1, Z2 = Z1_list[h], Z2_list[h]
        for l in range(b_list[h]):
            mask = (Z1[:,None]==l) & (Z2[None,:]==l)
            R = rbf(X1, X2, theta_hs[h][l])
            K_add += (sigma_hs[h]**2) * R * mask
    return K0 + K_add, var_n

def nll_ezgp(params, X, Zs, y, shapes):
    n = X.shape[0]
    K, var_n = build_cov_ezgp((X,X), (Zs,Zs), params, shapes)
    K[np.diag_indices(n)] += var_n
    try:
        L = np.linalg.cholesky(K)
    except np.linalg.LinAlgError:
        return np.inf
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))
    logdet = 2*np.sum(np.log(np.diag(L)))
    return 0.5*(y.T @ alpha + logdet + n*np.log(2*np.pi))[0]

def gp_predict_ezgp(params, X_train, Z_train, y_train,
                    X_test, Z_test, shapes):
    n_train = X_train.shape[0]
    Kxx, var_n = build_cov_ezgp((X_train, X_train),
                                (Z_train, Z_train),
                                params, shapes)
    Kxx[np.diag_indices(n_train)] += var_n
    L = np.linalg.cholesky(Kxx)
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y_train))
    Kxs, _ = build_cov_ezgp((X_train, X_test),
                            (Z_train, Z_test),
                            params, shapes)
    mu = (Kxs.T @ alpha).ravel()
    v = np.linalg.solve(L, Kxs)
    Kss, _ = build_cov_ezgp((X_test, X_test),
                            (Z_test, Z_test),
                            params, shapes)
    var = np.diag(Kss - v.T @ v)
    return mu, var

'''
def multi_start_optimize(n_restarts, x0, bounds,
                         objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    best_nll = np.inf
    best_theta = None
    lower = np.array([b[0] for b in bounds])
    upper = np.array([b[1] if b[1] is not None else np.inf
                      for b in bounds])
    for _ in range(n_restarts):
        x0_i = x0 * np.exp(np.random.randn(*x0.shape)*0.2)
        x0_i = np.minimum(np.maximum(x0_i, lower), upper)
        theta_i, nll_i, info = fmin_l_bfgs_b(
            objective_fn, x0_i, args=args,
            approx_grad=True, bounds=bounds,
            maxiter=maxiter, factr=factr, pgtol=pgtol
        )
        if nll_i < best_nll:
            best_nll, best_theta, best_info = nll_i, theta_i.copy(), info
    return best_theta
'''

def multi_start_optimize(x0, bounds, objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    # ignore n_restarts, do exactly one optimization from x0
    theta, nll, info = fmin_l_bfgs_b(
        objective_fn, x0, args=args, approx_grad=True,
        bounds=bounds, maxiter=maxiter, factr=factr, pgtol=pgtol
    )
    #print(f"NLL: {nll:.4f}, Converged: {info['warnflag']==0}")
    return theta


def run_one_simulation_ezgp(rep, cv_splits=5):
    # 1) Load data
    df = pd.read_csv("1_ordinal_feature_low_levels_100.csv")
    X_all = df[['x1','x2','x3','x4']].to_numpy()
    y_all = df['y'].to_numpy().reshape(-1,1)

    # 2) Encode & shapes
    categorical_cols = ['cat1']
    Z_lists, lookups = encode_categories(df, categorical_cols)
    b_list = [len(lookups[col]) for col in categorical_cols]
    shapes = {'p': X_all.shape[1], 'q': len(categorical_cols), 'b_list': b_list}

    # 3) Init x0 & bounds
    p, q = shapes['p'], shapes['q']
    parts = [1.0] + [0.5]*p
    for _ in range(q):
        parts += [1.0] + [0.5]*(p * b_list[_])
    parts += [1e-3]
    x0 = np.array(parts)
    bounds = [(1e-6, None)] * len(x0)

    # 4) 5-fold CV
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=rep)
    mses, r2s = [], []
    for tr, te in kf.split(X_all):
        X_tr, X_te = X_all[tr], X_all[te]
        y_tr, y_te = y_all[tr], y_all[te]
        Z_tr = [Z_lists[i][tr] for i in range(q)]
        Z_te = [Z_lists[i][te] for i in range(q)]

        theta_hat = multi_start_optimize(
            x0, bounds, nll_ezgp,
            args=(X_tr, Z_tr, y_tr, shapes)
        )
        y_pred, _ = gp_predict_ezgp(
            theta_hat, X_tr, Z_tr, y_tr,
            X_te, Z_te, shapes
        )

        mses.append(mean_squared_error(y_te, y_pred))
        r2s.append(r2_score(y_te, y_pred))

    mses = np.array(mses)
    r2s  = np.array(r2s)
    se_mse = mses.std(ddof=1) / np.sqrt(len(mses))
    se_r2  = r2s.std(ddof=1)  / np.sqrt(len(r2s))
    return mses.mean(), se_mse, r2s.mean(), se_r2

n_reps = 30
means_mse, ses_mse = [], []
means_r2 , ses_r2  = [], []

out_path = "EzGP-1 ordinal feature low levels 100 points.txt"
with open(out_path, "w") as fout:

    fout.write("=== Results for EzGP-1 ordinal feature low levels 100 points ===\n\n")
    for rep in range(1, n_reps+1):
        np.random.seed(rep)
        mean_mse, se_mse, mean_r2, se_r2 = run_one_simulation_ezgp(rep)
        means_mse.append(mean_mse); ses_mse.append(se_mse)
        means_r2.append(mean_r2); ses_r2.append(se_r2)

        line = (f"Rep {rep:2d}: CV MSE = {mean_mse:.5f} ± {se_mse:.5f} (SE),  "
                f"R² = {mean_r2:.4f} ± {se_r2:.4f} (SE)")
        print(line)
        fout.write(line + "\n")

    means_mse = np.array(means_mse)
    means_r2  = np.array(means_r2)

    overall_mse_mean = means_mse.mean()
    overall_mse_se   = means_mse.std(ddof=1) / np.sqrt(n_reps)
    overall_r2_mean  = means_r2.mean()
    overall_r2_se    = means_r2.std(ddof=1) / np.sqrt(n_reps)

    fout.write("\nOverall over 10 reps:\n")
    summary1 = f" MSE mean = {overall_mse_mean:.5f} ± {overall_mse_se:.5f} (SE)"
    summary2 = f"  R² mean = {overall_r2_mean:.4f} ± {overall_r2_se:.4f} (SE)"
    print(summary1); print(summary2)
    fout.write(summary1 + "\n"); fout.write(summary2 + "\n")

print(f"\nAll results have been saved to {out_path}")



def run_one_simulation_ezgp(rep, cv_splits=5):
    # 1) Load data
    df = pd.read_csv("1_ordinal_feature_high_levels_100.csv")
    X_all = df[['x1','x2','x3','x4']].to_numpy()
    y_all = df['y'].to_numpy().reshape(-1,1)

    # 2) Encode & shapes
    categorical_cols = ['cat1']
    Z_lists, lookups = encode_categories(df, categorical_cols)
    b_list = [len(lookups[col]) for col in categorical_cols]
    shapes = {'p': X_all.shape[1], 'q': len(categorical_cols), 'b_list': b_list}

    # 3) Init x0 & bounds
    p, q = shapes['p'], shapes['q']
    parts = [1.0] + [0.5]*p
    for _ in range(q):
        parts += [1.0] + [0.5]*(p * b_list[_])
    parts += [1e-3]
    x0 = np.array(parts)
    bounds = [(1e-6, None)] * len(x0)

    # 4) 5-fold CV
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=rep)
    mses, r2s = [], []
    for tr, te in kf.split(X_all):
        X_tr, X_te = X_all[tr], X_all[te]
        y_tr, y_te = y_all[tr], y_all[te]
        Z_tr = [Z_lists[i][tr] for i in range(q)]
        Z_te = [Z_lists[i][te] for i in range(q)]

        theta_hat = multi_start_optimize(
            x0, bounds, nll_ezgp,
            args=(X_tr, Z_tr, y_tr, shapes)
        )
        y_pred, _ = gp_predict_ezgp(
            theta_hat, X_tr, Z_tr, y_tr,
            X_te, Z_te, shapes
        )

        mses.append(mean_squared_error(y_te, y_pred))
        r2s.append(r2_score(y_te, y_pred))

    mses = np.array(mses)
    r2s  = np.array(r2s)
    se_mse = mses.std(ddof=1) / np.sqrt(len(mses))
    se_r2  = r2s.std(ddof=1)  / np.sqrt(len(r2s))
    return mses.mean(), se_mse, r2s.mean(), se_r2

n_reps = 100
means_mse, ses_mse = [], []
means_r2 , ses_r2  = [], []

out_path = "EzGP-1 ordinal feature high levels 100 points.txt"
with open(out_path, "w") as fout:

    fout.write("=== Results for EzGP-1 ordinal feature high levels 100 points ===\n\n")
    for rep in range(1, n_reps+1):
        np.random.seed(rep)
        mean_mse, se_mse, mean_r2, se_r2 = run_one_simulation_ezgp(rep)
        means_mse.append(mean_mse); ses_mse.append(se_mse)
        means_r2.append(mean_r2); ses_r2.append(se_r2)

        line = (f"Rep {rep:2d}: CV MSE = {mean_mse:.5f} ± {se_mse:.5f} (SE),  "
                f"R² = {mean_r2:.4f} ± {se_r2:.4f} (SE)")
        print(line)
        fout.write(line + "\n")

    means_mse = np.array(means_mse)
    means_r2  = np.array(means_r2)

    overall_mse_mean = means_mse.mean()
    overall_mse_se   = means_mse.std(ddof=1) / np.sqrt(n_reps)
    overall_r2_mean  = means_r2.mean()
    overall_r2_se    = means_r2.std(ddof=1) / np.sqrt(n_reps)

    fout.write("\nOverall over 10 reps:\n")
    summary1 = f" MSE mean = {overall_mse_mean:.5f} ± {overall_mse_se:.5f} (SE)"
    summary2 = f"  R² mean = {overall_r2_mean:.4f} ± {overall_r2_se:.4f} (SE)"
    print(summary1); print(summary2)
    fout.write(summary1 + "\n"); fout.write(summary2 + "\n")

print(f"\nAll results have been saved to {out_path}")


# Four ordinal features

import numpy as np
import pandas as pd
from scipy.optimize import fmin_l_bfgs_b
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score

def encode_categories(df, cols):
    Zs, lookups = [], {}
    for c in cols:
        codes, levels = pd.factorize(df[c], sort=True)
        Zs.append(codes)
        lookups[c] = dict(enumerate(levels))
    return Zs, lookups

def build_cov_ezgp(X_pair, Z_pair, params, shapes):
    X1, X2 = X_pair
    Z1_list, Z2_list = Z_pair
    p, q, b_list = shapes['p'], shapes['q'], shapes['b_list']
    idx = 0
    sigma0 = params[idx]; idx += 1
    theta0 = params[idx:idx+p]; idx += p
    sigma_hs, theta_hs = [], []
    for h in range(q):
        sigma_hs.append(params[idx]); idx += 1
        m_h = b_list[h]
        th = params[idx: idx + p*m_h].reshape(m_h, p)
        idx += p*m_h
        theta_hs.append(th)
    var_n = params[-1]
    def rbf(Xa, Xb, ls):
        diff2 = ((Xa[:,None,:] - Xb[None,:,:])**2)/(2*ls**2)
        return np.exp(-diff2.sum(axis=-1))
    K0 = (sigma0**2)*rbf(X1, X2, theta0)
    K_add = np.zeros_like(K0)
    for h in range(q):
        Z1, Z2 = Z1_list[h], Z2_list[h]
        for l in range(b_list[h]):
            mask = (Z1[:,None]==l) & (Z2[None,:]==l)
            R = rbf(X1, X2, theta_hs[h][l])
            K_add += (sigma_hs[h]**2) * R * mask
    return K0 + K_add, var_n

def nll_ezgp(params, X, Zs, y, shapes):
    n = X.shape[0]
    K, var_n = build_cov_ezgp((X,X), (Zs,Zs), params, shapes)
    K[np.diag_indices(n)] += var_n
    try:
        L = np.linalg.cholesky(K)
    except np.linalg.LinAlgError:
        return np.inf
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))
    logdet = 2*np.sum(np.log(np.diag(L)))
    return 0.5*(y.T @ alpha + logdet + n*np.log(2*np.pi))[0]

def gp_predict_ezgp(params, X_train, Z_train, y_train,
                    X_test, Z_test, shapes):
    n_train = X_train.shape[0]
    Kxx, var_n = build_cov_ezgp((X_train, X_train),
                                (Z_train, Z_train),
                                params, shapes)
    Kxx[np.diag_indices(n_train)] += var_n
    L = np.linalg.cholesky(Kxx)
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y_train))
    Kxs, _ = build_cov_ezgp((X_train, X_test),
                            (Z_train, Z_test),
                            params, shapes)
    mu = (Kxs.T @ alpha).ravel()
    v = np.linalg.solve(L, Kxs)
    Kss, _ = build_cov_ezgp((X_test, X_test),
                            (Z_test, Z_test),
                            params, shapes)
    var = np.diag(Kss - v.T @ v)
    return mu, var

'''
def multi_start_optimize(n_restarts, x0, bounds,
                         objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    best_nll = np.inf
    best_theta = None
    lower = np.array([b[0] for b in bounds])
    upper = np.array([b[1] if b[1] is not None else np.inf
                      for b in bounds])
    for _ in range(n_restarts):
        x0_i = x0 * np.exp(np.random.randn(*x0.shape)*0.2)
        x0_i = np.minimum(np.maximum(x0_i, lower), upper)
        theta_i, nll_i, info = fmin_l_bfgs_b(
            objective_fn, x0_i, args=args,
            approx_grad=True, bounds=bounds,
            maxiter=maxiter, factr=factr, pgtol=pgtol
        )
        if nll_i < best_nll:
            best_nll, best_theta, best_info = nll_i, theta_i.copy(), info
    return best_theta
'''

def multi_start_optimize(x0, bounds, objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    # ignore n_restarts, do exactly one optimization from x0
    theta, nll, info = fmin_l_bfgs_b(
        objective_fn, x0, args=args, approx_grad=True,
        bounds=bounds, maxiter=maxiter, factr=factr, pgtol=pgtol
    )
    #print(f"NLL: {nll:.4f}, Converged: {info['warnflag']==0}")
    return theta


def run_one_simulation_ezgp(rep, cv_splits=5):
    # 1) Load data
    df = pd.read_csv("4_independent_ordinal_features_low_levels_100.csv")
    X_all = df[['x1','x2','x3','x4']].to_numpy()
    y_all = df['y'].to_numpy().reshape(-1,1)

    # 2) Encode & shapes
    categorical_cols = ['cat1','cat2', 'cat3','cat4']
    Z_lists, lookups = encode_categories(df, categorical_cols)
    b_list = [len(lookups[col]) for col in categorical_cols]
    shapes = {'p': X_all.shape[1], 'q': len(categorical_cols), 'b_list': b_list}

    # 3) Init x0 & bounds
    p, q = shapes['p'], shapes['q']
    parts = [1.0] + [0.5]*p
    for _ in range(q):
        parts += [1.0] + [0.5]*(p * b_list[_])
    parts += [1e-3]
    x0 = np.array(parts)
    bounds = [(1e-6, None)] * len(x0)

    # 4) 5-fold CV
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=rep)
    mses, r2s = [], []
    for tr, te in kf.split(X_all):
        X_tr, X_te = X_all[tr], X_all[te]
        y_tr, y_te = y_all[tr], y_all[te]
        Z_tr = [Z_lists[i][tr] for i in range(q)]
        Z_te = [Z_lists[i][te] for i in range(q)]

        theta_hat = multi_start_optimize(
            x0, bounds, nll_ezgp,
            args=(X_tr, Z_tr, y_tr, shapes)
        )
        y_pred, _ = gp_predict_ezgp(
            theta_hat, X_tr, Z_tr, y_tr,
            X_te, Z_te, shapes
        )

        mses.append(mean_squared_error(y_te, y_pred))
        r2s.append(r2_score(y_te, y_pred))

    mses = np.array(mses)
    r2s  = np.array(r2s)
    se_mse = mses.std(ddof=1) / np.sqrt(len(mses))
    se_r2  = r2s.std(ddof=1)  / np.sqrt(len(r2s))
    return mses.mean(), se_mse, r2s.mean(), se_r2

n_reps = 30
means_mse, ses_mse = [], []
means_r2 , ses_r2  = [], []

out_path = "EzGP-4independent ordinal features low levels 100 points.txt"
with open(out_path, "w") as fout:

    fout.write("=== Results for EzGP-4 independent ordinal feature low levels 100 points ===\n\n")
    for rep in range(1, n_reps+1):
        np.random.seed(rep)
        mean_mse, se_mse, mean_r2, se_r2 = run_one_simulation_ezgp(rep)
        means_mse.append(mean_mse); ses_mse.append(se_mse)
        means_r2.append(mean_r2); ses_r2.append(se_r2)

        line = (f"Rep {rep:2d}: CV MSE = {mean_mse:.5f} ± {se_mse:.5f} (SE),  "
                f"R² = {mean_r2:.4f} ± {se_r2:.4f} (SE)")
        print(line)
        fout.write(line + "\n")

    means_mse = np.array(means_mse)
    means_r2  = np.array(means_r2)

    overall_mse_mean = means_mse.mean()
    overall_mse_se   = means_mse.std(ddof=1) / np.sqrt(n_reps)
    overall_r2_mean  = means_r2.mean()
    overall_r2_se    = means_r2.std(ddof=1) / np.sqrt(n_reps)

    fout.write("\nOverall over 10 reps:\n")
    summary1 = f" MSE mean = {overall_mse_mean:.5f} ± {overall_mse_se:.5f} (SE)"
    summary2 = f"  R² mean = {overall_r2_mean:.4f} ± {overall_r2_se:.4f} (SE)"
    print(summary1); print(summary2)
    fout.write(summary1 + "\n"); fout.write(summary2 + "\n")

print(f"\nAll results have been saved to {out_path}")



def run_one_simulation_ezgp(rep, cv_splits=5):
    # 1) Load data
    df = pd.read_csv("4_independent_ordinal_features_high_levels_100.csv")
    X_all = df[['x1','x2','x3','x4']].to_numpy()
    y_all = df['y'].to_numpy().reshape(-1,1)

    # 2) Encode & shapes
    categorical_cols = ['cat1','cat2', 'cat3','cat4']
    Z_lists, lookups = encode_categories(df, categorical_cols)
    b_list = [len(lookups[col]) for col in categorical_cols]
    shapes = {'p': X_all.shape[1], 'q': len(categorical_cols), 'b_list': b_list}

    # 3) Init x0 & bounds
    p, q = shapes['p'], shapes['q']
    parts = [1.0] + [0.5]*p
    for _ in range(q):
        parts += [1.0] + [0.5]*(p * b_list[_])
    parts += [1e-3]
    x0 = np.array(parts)
    bounds = [(1e-6, None)] * len(x0)

    # 4) 5-fold CV
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=rep)
    mses, r2s = [], []
    for tr, te in kf.split(X_all):
        X_tr, X_te = X_all[tr], X_all[te]
        y_tr, y_te = y_all[tr], y_all[te]
        Z_tr = [Z_lists[i][tr] for i in range(q)]
        Z_te = [Z_lists[i][te] for i in range(q)]

        theta_hat = multi_start_optimize(
            x0, bounds, nll_ezgp,
            args=(X_tr, Z_tr, y_tr, shapes)
        )
        y_pred, _ = gp_predict_ezgp(
            theta_hat, X_tr, Z_tr, y_tr,
            X_te, Z_te, shapes
        )

        mses.append(mean_squared_error(y_te, y_pred))
        r2s.append(r2_score(y_te, y_pred))

    mses = np.array(mses)
    r2s  = np.array(r2s)
    se_mse = mses.std(ddof=1) / np.sqrt(len(mses))
    se_r2  = r2s.std(ddof=1)  / np.sqrt(len(r2s))
    return mses.mean(), se_mse, r2s.mean(), se_r2

n_reps = 100
means_mse, ses_mse = [], []
means_r2 , ses_r2  = [], []

out_path = "EzGP-4independent ordinal features high levels 100 points.txt"
with open(out_path, "w") as fout:

    fout.write("=== Results for EzGP-4 independent ordinal feature high levels 100 points ===\n\n")
    for rep in range(1, n_reps+1):
        np.random.seed(rep)
        mean_mse, se_mse, mean_r2, se_r2 = run_one_simulation_ezgp(rep)
        means_mse.append(mean_mse); ses_mse.append(se_mse)
        means_r2.append(mean_r2); ses_r2.append(se_r2)

        line = (f"Rep {rep:2d}: CV MSE = {mean_mse:.5f} ± {se_mse:.5f} (SE),  "
                f"R² = {mean_r2:.4f} ± {se_r2:.4f} (SE)")
        print(line)
        fout.write(line + "\n")

    means_mse = np.array(means_mse)
    means_r2  = np.array(means_r2)

    overall_mse_mean = means_mse.mean()
    overall_mse_se   = means_mse.std(ddof=1) / np.sqrt(n_reps)
    overall_r2_mean  = means_r2.mean()
    overall_r2_se    = means_r2.std(ddof=1) / np.sqrt(n_reps)

    fout.write("\nOverall over 10 reps:\n")
    summary1 = f" MSE mean = {overall_mse_mean:.5f} ± {overall_mse_se:.5f} (SE)"
    summary2 = f"  R² mean = {overall_r2_mean:.4f} ± {overall_r2_se:.4f} (SE)"
    print(summary1); print(summary2)
    fout.write(summary1 + "\n"); fout.write(summary2 + "\n")

print(f"\nAll results have been saved to {out_path}")


# Ten ordinal features

import numpy as np
import pandas as pd
from scipy.optimize import fmin_l_bfgs_b
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score

def encode_categories(df, cols):
    Zs, lookups = [], {}
    for c in cols:
        codes, levels = pd.factorize(df[c], sort=True)
        Zs.append(codes)
        lookups[c] = dict(enumerate(levels))
    return Zs, lookups

def build_cov_ezgp(X_pair, Z_pair, params, shapes):
    X1, X2 = X_pair
    Z1_list, Z2_list = Z_pair
    p, q, b_list = shapes['p'], shapes['q'], shapes['b_list']
    idx = 0
    sigma0 = params[idx]; idx += 1
    theta0 = params[idx:idx+p]; idx += p
    sigma_hs, theta_hs = [], []
    for h in range(q):
        sigma_hs.append(params[idx]); idx += 1
        m_h = b_list[h]
        th = params[idx: idx + p*m_h].reshape(m_h, p)
        idx += p*m_h
        theta_hs.append(th)
    var_n = params[-1]
    def rbf(Xa, Xb, ls):
        diff2 = ((Xa[:,None,:] - Xb[None,:,:])**2)/(2*ls**2)
        return np.exp(-diff2.sum(axis=-1))
    K0 = (sigma0**2)*rbf(X1, X2, theta0)
    K_add = np.zeros_like(K0)
    for h in range(q):
        Z1, Z2 = Z1_list[h], Z2_list[h]
        for l in range(b_list[h]):
            mask = (Z1[:,None]==l) & (Z2[None,:]==l)
            R = rbf(X1, X2, theta_hs[h][l])
            K_add += (sigma_hs[h]**2) * R * mask
    return K0 + K_add, var_n

def nll_ezgp(params, X, Zs, y, shapes):
    n = X.shape[0]
    K, var_n = build_cov_ezgp((X,X), (Zs,Zs), params, shapes)
    K[np.diag_indices(n)] += var_n
    try:
        L = np.linalg.cholesky(K)
    except np.linalg.LinAlgError:
        return np.inf
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))
    logdet = 2*np.sum(np.log(np.diag(L)))
    return 0.5*(y.T @ alpha + logdet + n*np.log(2*np.pi))[0]

def gp_predict_ezgp(params, X_train, Z_train, y_train,
                    X_test, Z_test, shapes):
    n_train = X_train.shape[0]
    Kxx, var_n = build_cov_ezgp((X_train, X_train),
                                (Z_train, Z_train),
                                params, shapes)
    Kxx[np.diag_indices(n_train)] += var_n
    L = np.linalg.cholesky(Kxx)
    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y_train))
    Kxs, _ = build_cov_ezgp((X_train, X_test),
                            (Z_train, Z_test),
                            params, shapes)
    mu = (Kxs.T @ alpha).ravel()
    v = np.linalg.solve(L, Kxs)
    Kss, _ = build_cov_ezgp((X_test, X_test),
                            (Z_test, Z_test),
                            params, shapes)
    var = np.diag(Kss - v.T @ v)
    return mu, var

'''
def multi_start_optimize(n_restarts, x0, bounds,
                         objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    best_nll = np.inf
    best_theta = None
    lower = np.array([b[0] for b in bounds])
    upper = np.array([b[1] if b[1] is not None else np.inf
                      for b in bounds])
    for _ in range(n_restarts):
        x0_i = x0 * np.exp(np.random.randn(*x0.shape)*0.2)
        x0_i = np.minimum(np.maximum(x0_i, lower), upper)
        theta_i, nll_i, info = fmin_l_bfgs_b(
            objective_fn, x0_i, args=args,
            approx_grad=True, bounds=bounds,
            maxiter=maxiter, factr=factr, pgtol=pgtol
        )
        if nll_i < best_nll:
            best_nll, best_theta, best_info = nll_i, theta_i.copy(), info
    return best_theta
'''

def multi_start_optimize(x0, bounds, objective_fn, args,
                         maxiter=500, factr=1e7, pgtol=1e-8):
    # ignore n_restarts, do exactly one optimization from x0
    theta, nll, info = fmin_l_bfgs_b(
        objective_fn, x0, args=args, approx_grad=True,
        bounds=bounds, maxiter=maxiter, factr=factr, pgtol=pgtol
    )
    #print(f"NLL: {nll:.4f}, Converged: {info['warnflag']==0}")
    return theta


def run_one_simulation_ezgp(rep, cv_splits=5):
    # 1) Load data
    df = pd.read_csv("10_independent_ordinal_features.csv")
    X_all = df[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']].to_numpy()
    y_all = df['y'].to_numpy().reshape(-1,1)

    # 2) Encode & shapes
    categorical_cols = ['cat1','cat2','cat3','cat4', 'cat5','cat6','cat7','cat8', 'cat9','cat10']
    Z_lists, lookups = encode_categories(df, categorical_cols)
    b_list = [len(lookups[col]) for col in categorical_cols]
    shapes = {'p': X_all.shape[1], 'q': len(categorical_cols), 'b_list': b_list}

    # 3) Init x0 & bounds
    p, q = shapes['p'], shapes['q']
    parts = [1.0] + [0.5]*p
    for _ in range(q):
        parts += [1.0] + [0.5]*(p * b_list[_])
    parts += [1e-3]
    x0 = np.array(parts)
    bounds = [(1e-6, None)] * len(x0)

    # 4) 5-fold CV
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=rep)
    mses, r2s = [], []
    for tr, te in kf.split(X_all):
        X_tr, X_te = X_all[tr], X_all[te]
        y_tr, y_te = y_all[tr], y_all[te]
        Z_tr = [Z_lists[i][tr] for i in range(q)]
        Z_te = [Z_lists[i][te] for i in range(q)]

        theta_hat = multi_start_optimize(
            x0, bounds, nll_ezgp,
            args=(X_tr, Z_tr, y_tr, shapes)
        )
        y_pred, _ = gp_predict_ezgp(
            theta_hat, X_tr, Z_tr, y_tr,
            X_te, Z_te, shapes
        )

        mses.append(mean_squared_error(y_te, y_pred))
        r2s.append(r2_score(y_te, y_pred))

    mses = np.array(mses)
    r2s  = np.array(r2s)
    se_mse = mses.std(ddof=1) / np.sqrt(len(mses))
    se_r2  = r2s.std(ddof=1)  / np.sqrt(len(r2s))
    return mses.mean(), se_mse, r2s.mean(), se_r2

n_reps = 100
means_mse, ses_mse = [], []
means_r2 , ses_r2  = [], []

out_path = "EzGP-10independent ordinal features.txt"
with open(out_path, "w") as fout:

    fout.write("=== Results for EzGP-10independent ordinal features ===\n\n")
    for rep in range(1, n_reps+1):
        np.random.seed(rep)
        mean_mse, se_mse, mean_r2, se_r2 = run_one_simulation_ezgp(rep)
        means_mse.append(mean_mse); ses_mse.append(se_mse)
        means_r2.append(mean_r2); ses_r2.append(se_r2)

        line = (f"Rep {rep:2d}: CV MSE = {mean_mse:.5f} ± {se_mse:.5f} (SE),  "
                f"R² = {mean_r2:.4f} ± {se_r2:.4f} (SE)")
        print(line)
        fout.write(line + "\n")

    means_mse = np.array(means_mse)
    means_r2  = np.array(means_r2)

    overall_mse_mean = means_mse.mean()
    overall_mse_se   = means_mse.std(ddof=1) / np.sqrt(n_reps)
    overall_r2_mean  = means_r2.mean()
    overall_r2_se    = means_r2.std(ddof=1) / np.sqrt(n_reps)

    fout.write("\nOverall over 100 reps:\n")
    summary1 = f" MSE mean = {overall_mse_mean:.5f} ± {overall_mse_se:.5f} (SE)"
    summary2 = f"  R² mean = {overall_r2_mean:.4f} ± {overall_r2_se:.4f} (SE)"
    print(summary1); print(summary2)
    fout.write(summary1 + "\n"); fout.write(summary2 + "\n")

print(f"\nAll results have been saved to {out_path}")
